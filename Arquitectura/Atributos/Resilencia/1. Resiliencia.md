# Resiliencia

> Es la capacidad de reaccionar ante un fallo y a su vez recuperarse del mismo para seguir funcionando, minimizando cualquier tipo de afectación sobre el negocio.

La resiliencia por tanto no trata de evitar fallos, sino de aceptarlos y construir un servicio de forma que sea capaz de recuperarse y volver a un estado de funcionamiento completo lo antes posible.

Los sistemas Cloud-Native se fundamentan en arquitecturas distribuidas y, por tanto, se exponen a un mayor conjunto de casuísticas de error en comparación al modelo clásico de aplicación en monolito. Algunos ejemplos de situaciones de fallo son:

- Crecimientos inesperados en las latencias de red que pueden incurrir en timeouts de comunicación entre componentes y llegar a reducir la calidad del servicio.

- Microcortes de red causantes de errores de conectividad.

- Caída de un componente, con reinicio o cambio de localización, que debe gestionarse transparentemente al servicio.

- Sobrecarga de un componente que desencadena un incremento progresivo en su tiempo de respuesta y puede desencadenar finalmente errores de conexión.

- Orquestación de operaciones tales como rolling updates (estrategia de actualización del sistema que evita cualquier pérdida de servicio) o escalado/desescalado de servicios.

- Fallos de hardware.

A pesar de que las plataformas cloud pueden detectar y mitigar muchos de los fallos en la capa de infraestructura sobre la que se ejecutan las aplicaciones, para obtener un nivel de resiliencia adecuado de nuestro sistema, es necesario implementar ciertas prácticas o patrones a nivel de la aplicación o sistema software desplegado.

Hablemos ahora de qué técnicas o tecnologías nos ayudan a conseguir resiliencia en cada una de las capas presentadas: capa infraestructura y capa software.

## Infraestructura Resiliente

La resiliencia, a nivel hardware, puede conseguirse vía soluciones como por ejemplo fuentes de alimentación redundantes, unidades de almacenamiento con escritura duplicada (RAIDs), etc.

Sin embargo, sólo ciertos fallos quedarán cubiertos con estas protecciones, y tendremos que recurrir a otras técnicas para alcanzar los niveles de resiliencia deseados, como son la redundancia y la escalabilidad.

### Redundancia

La redundancia consiste en, tal y como indica la misma palabra, replicar cada uno de los elementos que conforman el servicio, de manera que cualquier tarea o parte de una tarea siempre pueda ser realizada por más de un componente.

Para ello hemos de añadir un mecanismo que permite repartir la carga de trabajo entre estas "copias" duplicadas dentro de cada grupo de trabajo, como por ejemplo, podría ser un balanceador de carga. Por otro lado, determinar el nivel de replicación necesario en un servicio dependerá de los requerimientos de negocio del mismo, y afectará tanto a su coste como a la complejidad del mismo.

Se recomienda identificar los flujos críticos dentro del servicio y añadir redundancia en cada punto de los flujos, evitando así crear "puntos únicos de fallo" (single point of failure). Estos puntos se refieren a aquellos componentes de nuestro sistema que en caso de fallo provocaría una caída total del mismo.

Es también común añadir redundancia multiregión con geo-replicación de la información y distribuir la carga mediante balanceo por DNS, dirigiendo así cada petición a la región adecuada en función de la distancia a su origen geográfico.

### Escalabilidad

> Diseñar sistemas escalables es fundamental también para conseguir resiliencia.

La escalabilidad o capacidad de ajustar los recursos a la carga de trabajo, ya sea incrementando o decrementando su número, es fundamental para evitar situaciones de fallo como timeouts de comunicación por tiempos de respuesta demasiado elevados, caídas de servicio por colapso de trabajo, o la degradación de los subsistemas de almacenamiento por ingestión masiva de información,...

Existen dos tipos de escalado:

- Escalado vertical o scale up, que consiste en incrementar la potencia de una máquina (ya sea en CPU, memoria, especio de almacenamiento...)

- Escalado horizontal o scale out, que supone añadir más máquinas.

La capacidad de escalar horizontalmente un sistema está muy interrelacionada con disponer de redundancia. Podríamos ver la primera como un plano superior a la segunda, es decir, un sistema no-redundante no puede ser escalable horizontalmente. A su vez, podemos conseguir escalabilidad horizontal sobre redundancia si añadimos una retroalimentación que permita determinar a partir de la carga en tiempo real del sistema en qué medida se debe crecer o decrecer en recursos para ajustarse óptimamente a las necesidades demandadas en cada momento.

Fijémonos que en este punto estamos también estableciendo una relación con la capacidad de observabilidad, que será la encargada de proporcionar las métricas necesarias para monitorizar la carga y automatizar los sistemas de autoescalado.

Existen librerías en muchos lenguajes para implementar estas técnicas y también se pueden recurrir a soluciones más ortogonales como los Service Mesh para facilitarnos esta labor y desacoplar completamente nuestra lógica de negocio.

## Software Resiliente

Cómo ya se avanzaba al inicio de este post, es imprescindible incorporar la resiliencia dentro del diseño del propio software para poder afrontar exitosamente todos los retos de los sistemas distribuidos.

La lógica del servicio debe tratar al fallo como un caso más y no como una excepción, debe definir cómo actuar en caso de fallo, y determinar la acción de contingencia cuando el camino preferente no esté disponible. Esto último se conoce cómo acción fallback o configuración de respaldo para ese caso de error.

## Patrones arquitecturales

A parte del patrón fallback, existen un conjunto de patrones de arquitectura orientados a proveer de resiliencia un sistema distribuido, como por ejemplo son:

1) Cortocircuito (Circuit Breaker): este patrón contribuye a que un servicio pueda recuperarse o desacoplarse tanto de caídas de rendimiento por sobrecargas en un subsistema como ante apagones completos de partes de la aplicación.

2) Timeouts: el mero hecho de limitar el tiempo en qué el emisor de una petición va esperar su respuesta, puede ser la clave que evite sobrecargas por acumulación de recursos facilitando así la resiliencia del sistema.

3) Reintentos: las dos técnicas anteriores, cortocircuito y timeouts, han introducido ya indirectamente la importancia de realizar reintentos como concepto base para obtener resiliencia. Pero, ¿es posible incorporar reintentos en las comunicaciones entre componentes de forma gratuita?

4) Caché: ahora que conocemos el porqué de incorporar reintentos, podemos entender los poderes de este nuevo patrón que son las cachés aplicadas a resiliencia.

5) Bulkhead: este último patrón consiste en dividir el sistema distribuido en partes "aisladas" e independientes, también llamadas pools, de forma que en caso que falle una de ellas las demás puedan seguir funcionando normalmente.

## Tests de resiliencia

Como hemos dicho anteriormente, en un sistema distribuido hay tantos componentes interactuando entre ellos que la probabilidad de cosas que pueden salir mal es muy grande. Hardware, red, sobrecarga de tráfico, etc. pueden fallar.

Hemos comentado varias técnicas para conseguir que nuestro software sea resiliente y se minimice el impacto de esos fallos. Pero bien, ¿tenemos alguna forma de comprobar la resiliencia de nuestro sistema? La respuesta es sí, y se llama “Chaos Engineering”.

### ¿Qué es Chaos Engineering?

Es una disciplina de experimentación en infraestructura que saca a la luz las debilidades sistémicas. Este proceso empírico de verificación conduce a sistemas más resistentes y genera confianza sobre la capacidad de éstos a resistir situaciones turbulentas.

> Es necesario identificar las debilidades del sistema antes de que se manifiesten en comportamientos aberrantes con afectación generalizada a todo el sistema.

## Conclusiones

El enfoque más tradicional a la hora de construir sistemas era tratar al fallo como un evento excepcional fuera del camino exitoso de ejecución, y por lo tanto no se contemplaba en el diseño base del corazón del servicio.

Esto ha cambiado radicalmente en el mundo Cloud-native, dado que en arquitecturas distribuídas las situaciones de fallo aparecen con normalidad y recurrentemente en alguna pieza del conjunto y eso debe considerarse y asumirse desde el primer momento y dentro del propio diseño.

Así cuando hablamos de resiliencia nos referimos a esta característica que permite a los servicios responder y recuperarse a fallos limitando al máximo los efectos sobre el conjunto del sistema y reduciendo a la mínima expresión la afectación sobre el mismo.

> Conseguir sistemas resilientes no únicamente impacta en la calidad del servicio o aplicación, sino que también permite ganar más eficiencia en costes y, sobre todo, no perder oportunidades de negocio por pérdidas de servicio.